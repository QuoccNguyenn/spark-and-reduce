{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpfTN6vUzPmK",
        "outputId": "e3d95a65-b3a1-40d6-be9f-2cb652887578"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrXAzGuw1GIV"
      },
      "source": [
        "## **TẠO DATA FRAME**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD_iP4xb240m"
      },
      "source": [
        "from pyspark import SparkContext\r\n",
        "#sc = SparkContext()\r\n",
        "sqlContext = SQLContext(sc)\r\n",
        "\r\n",
        "from pyspark.sql import Row\r\n",
        "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\r\n",
        "rdd = sc.parallelize(l)\r\n",
        "people = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\r\n",
        "schemaPeople = sqlContext.createDataFrame(people)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A501aqCk30Rm",
        "outputId": "e1825133-9471-4e80-ac0f-73b4e837b2a6"
      },
      "source": [
        "type(schemaPeople)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxYPz5ZV0bdD"
      },
      "source": [
        "## **Tạo DataFrames từ danh sách các hàng**"
      ]
    }
  ]
}